Kinesis Project Steps Explanation [ EC2(Simulaton data) > Kinesis Data Streams > Apache Flink (Viewing the data) ]

Step 1:
Go to Kinesis -> Kinesis Data Streams
  -> Enter Stream name
  -> Data Stream: Provisioned or On-Demand
  -> Provisioned Shards - 1   (it will provision the data to process)
  Create a data stream

Step 2: To send the data to Kinesis
Go to EC2 -> Create and Launch Instance
  -> Goto launch instance, create vim script.py (code is available in script.py, use it)
  -> Mostly Python will be available, check python3 --version
  -> install pip - yum install python-pip -y  (- Hyphen)  (pip - python package manager)
  -> install boto3 - pip install boto3
  -> run - python3 script.py ( you will get an error because we have not configured the EC2 with resources)
  -> Create IAM - SecurityCredentials - create access key - use access & secret keys in aws configure in Ec2
  -> after aws configure, run 'python3 script.py' to send data to Kinesis

  => We can check the incoming data in Kinesis Data Streams > Monitoring, don't stop the send code in EC2
Step 3:
=> In Kinesis Data Streams > Applications > Consumers > Managed Apache Flink - process data in realtime
  -> Click process data in real-time > Apache Flink Studio Notebook, create it
      -> provide notebook name, create Glue database with name, select it & create studio notebook.

      -> Once we run the studio notebook, the data will be sent to Kinesis Data Streams, and then Apache Flink will take the data.
      => IN StudioNotebook page open in Apache Zeppelin > create notebook, provide name, create it.
          -> Use test.sql query to see the data that will come from the EC2 server code.
           


     


